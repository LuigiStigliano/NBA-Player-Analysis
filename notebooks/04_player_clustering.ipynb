{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clustering dei Giocatori\n",
    "\n",
    "**Obiettivo:** Raggruppare i giocatori in cluster omogenei basati sul loro stile di gioco. Questo è il cuore del mio progetto, dove cercherò di scoprire i \"profili\" statistici che definiscono i giocatori moderni.\n",
    "\n",
    "1.  **Caricamento e Selezione Dati:** Carico il dataset arricchito e seleziono solo la stagione più rappresentativa di ogni giocatore.\n",
    "2.  **Preparazione delle Feature:** Scelgo le statistiche più significative e le standardizzo.\n",
    "3.  **Determinazione di 'k':** Uso l'Elbow Method per trovare il numero ottimale di cluster.\n",
    "4.  **Addestramento e Valutazione:** Addestro il modello K-Means e valuto la qualità dei cluster con il Silhouette Score.\n",
    "5.  **Salvataggio dei Risultati:** Salvo il DataFrame finale con l'ID del cluster per ogni giocatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql.functions import col, max, row_number, when\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.clustering.models import (\n",
    "    assign_clusters, evaluate_clustering, \n",
    "    prepare_features_for_clustering, train_kmeans_model\n",
    ")\n",
    "from src.config.spark_config import SPARK_CONFIG\n",
    "from src.utils.helpers import get_spark_session, save_dataframe\n",
    "\n",
    "project_root = os.path.abspath(os.path.join('..'))\n",
    "processed_data_dir = os.path.join(project_root, \"data\", \"processed\")\n",
    "adv_metrics_path = os.path.join(processed_data_dir, \"players_advanced_metrics.parquet\")\n",
    "output_path = os.path.join(processed_data_dir, \"players_clustered.parquet\")\n",
    "\n",
    "spark = get_spark_session(\n",
    "    app_name=\"NBA_Player_Clustering\",\n",
    "    driver_memory=SPARK_CONFIG[\"driver_memory\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 1: Caricamento Dati e Selezione dell'Ultima Stagione\n",
    "\n",
    "Per analizzare lo stile \"attuale\" di un giocatore, ho bisogno di selezionare una singola stagione rappresentativa. Ho sviluppato una logica per prendere l'ultima stagione giocata, gestendo anche i casi di giocatori scambiati che hanno una riga 'TOT'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = spark.read.parquet(adv_metrics_path)\n",
    "\n",
    "window_spec_latest_season = Window.partitionBy(\"player\").orderBy(col(\"season\").desc(), col(\"g\").desc())\n",
    "\n",
    "df_with_rank = df_input.withColumn(\"rank\", row_number().over(window_spec_latest_season))\n",
    "\n",
    "df_latest_season_only = df_with_rank.filter(col(\"rank\") == 1)\n",
    "\n",
    "df_with_priority = df_latest_season_only.withColumn(\n",
    "    \"priority\",\n",
    "    when(col(\"tm\") == \"TOT\", 1).otherwise(2)\n",
    ")\n",
    "\n",
    "final_window_spec = Window.partitionBy(\"player\", \"season\").orderBy(\"priority\", \"g\")\n",
    "df_with_final_rank = df_with_priority.withColumn(\"final_rank\", row_number().over(final_window_spec))\n",
    "\n",
    "df_for_clustering_input = df_with_final_rank.filter(col(\"final_rank\") == 1)\n",
    "\n",
    "feature_cols = [\n",
    "    'pts_per_36_min', 'trb_per_36_min', 'ast_per_36_min', \n",
    "    'stl_per_36_min', 'blk_per_36_min', 'tov_per_36_min',\n",
    "    'ts_pct_calc'\n",
    "]\n",
    "\n",
    "df_for_clustering = df_for_clustering_input.select([\"player\", \"season\"] + feature_cols).na.drop()\n",
    "print(f\"Numero di giocatori idonei per il clustering: {df_for_clustering.count()}\")\n",
    "df_for_clustering.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretazione dell'output\n",
    "\n",
    "L'output mi mostra quanti giocatori userò per il clustering e le sette feature che ho scelto. Questo sarà il mio input per l'algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 2: Preparazione e Scaling delle Feature\n",
    "\n",
    "K-Means è sensibile alla scala delle variabili, quindi devo standardizzarle. In questo modo, tutte le feature contribuiranno equamente al calcolo della distanza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = prepare_features_for_clustering(df_for_clustering, feature_cols)\n",
    "\n",
    "df_prepared.select(\"player\", \"features_scaled\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretazione dell'output\n",
    "\n",
    "La colonna `features_scaled` contiene i vettori con i valori standardizzati, pronti per essere usati dal modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 3: Determinazione del Numero Ottimale di Cluster (Elbow Method)\n",
    "\n",
    "Una domanda fondamentale è: \"quanti gruppi (k) devo creare?\". L'Elbow Method mi aiuta a rispondere. Calcolo il costo per diversi valori di 'k' e cerco il \"gomito\" nel grafico, che rappresenta un buon compromesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = []\n",
    "k_range = range(2, 15)\n",
    "print(\"Calcolo del costo WSSSE per diversi k...\")\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(featuresCol='features_scaled', k=k, seed=42)\n",
    "    model = kmeans.fit(df_prepared)\n",
    "    cost.append(model.summary.trainingCost)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_range, cost, 'bx-')\n",
    "plt.xlabel('k (Numero di Cluster)')\n",
    "plt.ylabel('Costo (WSSSE)')\n",
    "plt.title('Elbow Method per la Scelta Ottimale di k')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisi del Gomito\n",
    "\n",
    "Il grafico mostra un \"gomito\" evidente intorno a `k=6`. Dopo questo punto, aggiungere altri cluster non porta grandi benefici. Quindi, ho scelto **`k=6`** perché mi dà un buon numero di profili mantenendo i cluster interpretabili."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 4: Addestramento del Modello Finale e Valutazione\n",
    "\n",
    "Ora che ho scelto `k=6`, addestro il modello finale e assegno ogni giocatore a un cluster. Poi valuto la qualità del clustering con il Silhouette Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_optimal = 6\n",
    "print(f\"Addestramento del modello K-Means finale con k={k_optimal}...\")\n",
    "\n",
    "kmeans_model = train_kmeans_model(df_prepared, k=k_optimal)\n",
    "predictions_df = assign_clusters(kmeans_model, df_prepared)\n",
    "\n",
    "print(\"Esempi di giocatori con cluster assegnato:\")\n",
    "predictions_df.select(\"player\", \"season\", \"cluster_id\").show(10)\n",
    "\n",
    "silhouette_score = evaluate_clustering(predictions_df)\n",
    "print(f\"Punteggio Silhouette (validità del clustering): {silhouette_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretazione dell'output\n",
    "\n",
    "La tabella mi mostra l'ID del cluster (da 0 a 5) per ogni giocatore. Il Silhouette Score è positivo, il che mi dice che i cluster sono ragionevolmente ben definiti. È un buon risultato per dati reali come questi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 5: Salvataggio dei Risultati del Clustering\n",
    "\n",
    "Salvo il DataFrame con le assegnazioni dei cluster. Questo file sarà l'input per l'ultimo notebook, dove interpreterò i profili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_save = [\"player\", \"season\"] + feature_cols + [\"cluster_id\"]\n",
    "df_to_save = predictions_df.select(columns_to_save)\n",
    "\n",
    "save_dataframe(df_to_save, output_path)\n",
    "\n",
    "print(f\"Risultati del clustering salvati con successo in '{output_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusione e Prossimi Passi\n",
    "\n",
    "Ho completato la parte di machine learning. Ho preparato i dati, scelto 'k', addestrato il modello e assegnato i cluster.\n",
    "\n",
    "Nel prossimo notebook, `05_cluster_analysis_and_visualization.ipynb`, mi tufferò nell'analisi di questi cluster per capire cosa rappresentano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
